df_many_models <- tibble(K = seq(3, 10, by = 1)) %>%
mutate(topic_model = map (
.x = K,
.f = ~ stm(sparse_mat,
K = .x,
verbose = FALSE)
))
df_diagnostics <- df_many_models %>%
mutate(exclusivity = map(topic_model, exclusivity),
semantic_coherence = map(topic_model, semanticCoherence, sparse_mat),
residual = map(topic_model, checkResiduals, sparse_mat),
bound =  map_dbl(topic_model, function(x) max(x$convergence$bound)),
lfact = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
lbound = bound + lfact,
iterations = map_dbl(topic_model, function(x) length(x$convergence$bound)))
df_diagnostics %>%
transmute(K,
`Lower bound` = lbound,
Residuals = map_dbl(residual, "dispersion"),
`Semantic coherence` = map_dbl(semantic_coherence, mean)) %>%
gather(Metric, Value, -K) %>%
ggplot(aes(K, Value, color = Metric)) +
geom_line(linewidth = 1.5, alpha = 0.7, show.legend = FALSE) +
facet_wrap(~Metric, scales = "free_y") +
labs(x = "K (number of topics)",
y = NULL,
title = "Model diagnostics by number of topics")
df_diagnostics %>%
select(K, exclusivity, semantic_coherence) %>%
unnest(cols = c(exclusivity, semantic_coherence)) %>%
filter(K %in% c(5, 25, 50)) %>%
mutate(K = as.factor(K)) %>%
ggplot(aes(semantic_coherence, exclusivity, color = K)) +
geom_point(size = 2, alpha = 0.7) +
labs(x = "Semantic coherence",
y = "Exclusivity",
title = "Comparing exclusivity and semantic coherence",
subtitle = "Models with fewer topics have higher semantic coherence for more topics, but lower exclusivity")
df_diagnostics %>%
select(K, exclusivity, semantic_coherence) %>%
unnest(cols = c(exclusivity, semantic_coherence)) %>%
filter(K %in% c(3, 5, 7)) %>%
mutate(K = as.factor(K)) %>%
ggplot(aes(semantic_coherence, exclusivity, color = K)) +
geom_point(size = 2, alpha = 0.7) +
labs(x = "Semantic coherence",
y = "Exclusivity",
title = "Comparing exclusivity and semantic coherence",
subtitle = "Models with fewer topics have higher semantic coherence for more topics, but lower exclusivity")
topic_model <- stm(sparse_mat,
K = 25, # K is the number of 'topics' (clusters)
verbose = FALSE)
topic_model <- stm(sparse_mat,
K = 5, # K is the number of 'topics' (clusters)
verbose = FALSE)
p_topic <- tidy(topic_model, matrix = "frex") %>%
group_by(topic) %>%
slice_head(n = 10) %>%
mutate(topic = paste0("topic ", topic)) %>%
mutate(size = row_number()) %>%
ggplot(aes(label = term)) +
geom_text_wordcloud(aes(size = size)) +
scale_size_continuous(range = c(3, 4)) +
facet_wrap(vars(topic), nrow = 1) +
theme_classic()
# Topic probabilities
group_gamma <- tidy(
topic_model,
matrix = "gamma",
document_names = rownames(sparse_mat)) %>%
mutate(chapter = factor(document)) %>%
dplyr::select(chapter, topic, gamma) %>%
mutate(topic = factor(topic)
)
p_gamma <- group_gamma %>%
filter(gamma > 0.01 ) %>%
ggplot(aes(x = topic, y = gamma, color = topic)) +
geom_point(aes(alpha = gamma)) +
geom_text_repel(aes(alpha = gamma, label = chapter), size = 5,
max.overlaps = 50) +
labs(y = expression(gamma), x = "") +
ggtitle("Corpus (chapter) strength of association with each topic") +
theme(legend.position = "none",
axis.text.x = element_blank())
(p_gamma / p_topic) + plot_layout(heights = c(2, 1))
df_avatar
df_avatar %>% count(book)
df_avatar %>% count(writer)
df_avatar %>% count(director)
p_topic <- tidy(topic_model, matrix = "frex") %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
mutate(size = row_number()) %>%
ggplot(aes(label = term)) +
geom_text_wordcloud(aes(size = size)) +
scale_size_continuous(range = c(3, 4)) +
facet_wrap(vars(topic), nrow = 1) +
theme_classic()
# Topic probabilities
group_gamma <- tidy(
topic_model,
matrix = "gamma",
document_names = rownames(sparse_mat)) %>%
mutate(chapter = factor(document)) %>%
dplyr::select(chapter, topic, gamma) %>%
mutate(topic = factor(topic)
)
p_gamma <- group_gamma %>%
filter(gamma > 0.01 ) %>%
ggplot(aes(x = topic, y = gamma, color = topic)) +
geom_point(aes(alpha = gamma)) +
geom_text_repel(aes(alpha = gamma, label = chapter), size = 5,
max.overlaps = 50) +
labs(y = expression(gamma), x = "") +
ggtitle("Corpus (chapter) strength of association with each topic") +
theme(legend.position = "none",
axis.text.x = element_blank())
(p_gamma / p_topic) + plot_layout(heights = c(2, 1))
(p_gamma / p_topic) + plot_layout(heights = c(2, 1))
df_avatar %>%
count(character, sort = TRUE) %>%
filter(character != "Scene Description") %>%
# only look at characters that have at least 100 lines across all of Avatar
#filter(n > 100) %>%
pull(character)
df_avatar %>% count(director)
df_avatar
df_avatar %>%
count(director)
df_tokens <- df_avatar %>%
# filter for our speaking characters
#filter(character %in% speaking_characters) %>%
group_by(director) %>%
unnest_tokens(word, character_words) %>%
# remove stop words (uninteresting words like of, from, and, the, etc.)
anti_join(get_stopwords(), by = join_by(word))
head(df_tokens)
df_avatar %>%
# filter for our speaking characters
#filter(character %in% speaking_characters) %>%
group_by(director) %>%
unnest_tokens(word, character_words)
df_avatar %>%
# filter for our speaking characters
#filter(character %in% speaking_characters) %>%
group_by(director)
df_tokens <- df_avatar %>%
# filter for our speaking characters
#filter(character %in% speaking_characters) %>%
group_by(director) %>%
unnest_tokens(word, full_text) %>%
# remove stop words (uninteresting words like of, from, and, the, etc.)
anti_join(get_stopwords(), by = join_by(word))
head(df_tokens)
sparse_mat <- df_tokens %>%
# count number of times a word is used by each character
dplyr::count(character, word) %>%
# filter for words that appear at least 3 times
filter(n > 3) %>%
# create sparse matrix
cast_sparse(character, word, n)
sparse_mat <- df_tokens %>%
# count number of times a word is used by each character
dplyr::count(director, word) %>%
# filter for words that appear at least 3 times
filter(n > 3) %>%
# create sparse matrix
cast_sparse(character, word, n)
sparse_mat <- df_tokens %>%
# count number of times a word is used by each character
dplyr::count(director, word) %>%
# filter for words that appear at least 3 times
filter(n > 3) %>%
# create sparse matrix
cast_sparse(director, word, n)
dim(sparse_mat)
sparse_mat[1:10, 1:10]
topic_model <- stm(sparse_mat,
K = 4, # K is the number of 'topics' (clusters)
verbose = FALSE)
p_topic <- tidy(topic_model, matrix = "frex") %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
mutate(size = row_number()) %>%
ggplot(aes(label = term)) +
geom_text_wordcloud(aes(size = size)) +
scale_size_continuous(range = c(3, 4)) +
facet_wrap(vars(topic), nrow = 1) +
theme_classic()
# Topic probabilities
group_gamma <- tidy(
topic_model,
matrix = "gamma",
document_names = rownames(sparse_mat)) %>%
mutate(chapter = factor(document)) %>%
dplyr::select(chapter, topic, gamma) %>%
mutate(topic = factor(topic)
)
p_gamma <- group_gamma %>%
filter(gamma > 0.01 ) %>%
ggplot(aes(x = topic, y = gamma, color = topic)) +
geom_point(aes(alpha = gamma)) +
geom_text_repel(aes(alpha = gamma, label = chapter), size = 5,
max.overlaps = 50) +
labs(y = expression(gamma), x = "") +
ggtitle("Corpus (chapter) strength of association with each topic") +
theme(legend.position = "none",
axis.text.x = element_blank())
(p_gamma / p_topic) + plot_layout(heights = c(2, 1))
(p_gamma / p_topic) + plot_layout(heights = c(2, 1))
df_avatar
ratings_raw <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-17/office_ratings.csv")
ratings_raw
afrisenti <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-28/afrisenti.csv')
afrisenti
install.packages("shrute")
library(shrute)
install.packages("shrute")
library(shrute)
install.packages("schrute")
library(schrute)
schrute::theoffice
schrute::theoffice
df_office <- schrute::theoffice
df_office %>% count(character)
df_office %>%
count(character, sort = TRUE)
df_office %>%
count(character, sort = TRUE) %>%
head(20)
df_office %>%
count(character, sort = TRUE) %>%
filter(n > 500)
df_office %>%
count(character, sort = TRUE) %>%
filter(n > 500) %>%
pull(character)
speaking_characters <- df_office %>%
count(character, sort = TRUE) %>%
# select only characters with at least 500 lines across all seasons
filter(n > 500) %>%
pull(character)
df_tokens <- df_office %>%
# filter for our speaking characters
filter(character %in% speaking_characters) %>%
group_by(character) %>%
unnest_tokens(word, text) %>%
# remove stop words (uninteresting words like of, from, and, the, etc.)
anti_join(get_stopwords(), by = join_by(word))
head(df_tokens)
sparse_mat <- df_tokens %>%
# count number of times a word is used by each character
dplyr::count(character, word) %>%
# filter for words that appear at least 3 times
filter(n > 3) %>%
# create sparse matrix
cast_sparse(character, word, n)
dim(sparse_mat)
sparse_mat[1:10, 1:10]
topic_model <- stm(sparse_mat,
K = 5, # K is the number of 'topics' (clusters)
verbose = FALSE)
topic_model <- stm(sparse_mat,
K = 5, # K is the number of 'topics' (clusters)
verbose = FALSE)
summary(topic_model)
df_many_models <- tibble(K = seq(3, 10, by = 1)) %>%
mutate(topic_model = map (
.x = K,
.f = ~ stm(sparse_mat,
K = .x,
verbose = FALSE)
))
head(df_many_models)
df_diagnostics <- df_many_models %>%
mutate(exclusivity = map(topic_model, exclusivity),
semantic_coherence = map(topic_model, semanticCoherence, sparse_mat),
residual = map(topic_model, checkResiduals, sparse_mat),
bound =  map_dbl(topic_model, function(x) max(x$convergence$bound)),
lfact = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
lbound = bound + lfact,
iterations = map_dbl(topic_model, function(x) length(x$convergence$bound)))
df_diagnostics %>%
transmute(K,
`Lower bound` = lbound,
Residuals = map_dbl(residual, "dispersion"),
`Semantic coherence` = map_dbl(semantic_coherence, mean)) %>%
gather(Metric, Value, -K) %>%
ggplot(aes(K, Value, color = Metric)) +
geom_line(linewidth = 1.5, alpha = 0.7, show.legend = FALSE) +
facet_wrap(~Metric, scales = "free_y") +
labs(x = "K (number of topics)",
y = NULL,
title = "Model diagnostics by number of topics")
df_diagnostics %>%
select(K, exclusivity, semantic_coherence) %>%
unnest(cols = c(exclusivity, semantic_coherence)) %>%
#filter(K %in% c(3, 5, 7)) %>%
mutate(K = as.factor(K)) %>%
ggplot(aes(semantic_coherence, exclusivity, color = K)) +
geom_point(size = 2, alpha = 0.7) +
labs(x = "Semantic coherence",
y = "Exclusivity",
title = "Comparing exclusivity and semantic coherence",
subtitle = "Models with fewer topics have higher semantic coherence for more topics, but lower exclusivity")
df_diagnostics %>%
select(K, exclusivity, semantic_coherence) %>%
unnest(cols = c(exclusivity, semantic_coherence)) %>%
filter(K %in% c(3, 5, 7)) %>%
mutate(K = as.factor(K)) %>%
ggplot(aes(semantic_coherence, exclusivity, color = K)) +
geom_point(size = 2, alpha = 0.7) +
labs(x = "Semantic coherence",
y = "Exclusivity",
title = "Comparing exclusivity and semantic coherence",
subtitle = "Models with fewer topics have higher semantic coherence for more topics, but lower exclusivity")
topic_model <- stm(sparse_mat,
K = 5, # K is the number of 'topics' (clusters)
verbose = FALSE)
p_topic <- tidy(topic_model, matrix = "frex") %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
mutate(size = row_number()) %>%
ggplot(aes(label = term)) +
geom_text_wordcloud(aes(size = size)) +
scale_size_continuous(range = c(3, 4)) +
facet_wrap(vars(topic), nrow = 1) +
theme_classic()
# Topic probabilities
group_gamma <- tidy(
topic_model,
matrix = "gamma",
document_names = rownames(sparse_mat)) %>%
mutate(chapter = factor(document)) %>%
dplyr::select(chapter, topic, gamma) %>%
mutate(topic = factor(topic)
)
p_gamma <- group_gamma %>%
filter(gamma > 0.01 ) %>%
ggplot(aes(x = topic, y = gamma, color = topic)) +
geom_point(aes(alpha = gamma)) +
geom_text_repel(aes(alpha = gamma, label = chapter), size = 5,
max.overlaps = 50) +
labs(y = expression(gamma), x = "") +
ggtitle("Corpus (chapter) strength of association with each topic") +
theme(legend.position = "none",
axis.text.x = element_blank())
(p_gamma / p_topic) + plot_layout(heights = c(2, 1))
summary(topic_model)
tidy(topic_model, matrix = "frex")
tidy(topic_model, matrix = "frex")
tidy(topic_model)
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model))
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model))
group_by(topic) %>%
slice_head(n = 20)
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20)
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
ggplot(aes(x = beta, y = term)) +
geom_col()
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
ggplot(aes(x = beta, y = term)) +
geom_col() +
facet_wrap(vars(topic))
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
ggplot(aes(x = beta, y = term)) +
geom_col() +
facet_wrap(vars(topic), scales = "free")
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
ggplot(aes(x = beta, y = reorder(term, by = beta))) +
geom_col() +
facet_wrap(vars(topic), scales = "free", nrow = 1)
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
ggplot(aes(x = beta, y = reorder(term, desc(beta)))) +
geom_col() +
facet_wrap(vars(topic), scales = "free", nrow = 1)
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
ggplot(aes(x = beta, y = reorder(term, asc(beta)))) +
geom_col() +
facet_wrap(vars(topic), scales = "free", nrow = 1)
help(desc)
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
ggplot(aes(x = beta, y = reorder(term, beta))) +
geom_col() +
facet_wrap(vars(topic), scales = "free", nrow = 1)
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
ggplot(aes(x = beta, y = reorder(term, beta), fill = topic)) +
geom_col() +
labs(y = "Word") +
facet_wrap(vars(topic), scales = "free", nrow = 1)
tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
ggplot(aes(x = beta, y = reorder(term, beta), fill = topic)) +
geom_col() +
labs(y = "Word") +
facet_wrap(vars(topic), scales = "free", nrow = 1)
# Topic probabilities
group_gamma <- tidy(
topic_model,
matrix = "gamma",
document_names = rownames(sparse_mat)) %>%
mutate(chapter = factor(document)) %>%
dplyr::select(chapter, topic, gamma) %>%
mutate(topic = factor(topic)
)
p_gamma <- group_gamma %>%
filter(gamma > 0.01 ) %>%
ggplot(aes(x = topic, y = gamma, color = topic)) +
geom_point(aes(alpha = gamma)) +
geom_text_repel(aes(alpha = gamma, label = chapter), size = 5,
max.overlaps = 50) +
labs(y = expression(gamma), x = "") +
ggtitle("Corpus (chapter) strength of association with each topic") +
theme(legend.position = "none",
axis.text.x = element_blank())
(p_gamma / p_topic)
p_beta <- tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
ggplot(aes(x = beta, y = reorder(term, beta), fill = topic)) +
geom_col() +
labs(y = "Word") +
facet_wrap(vars(topic), scales = "free", nrow = 1)
(p_gamma / p_beta)
topic_model <- stm(sparse_mat,
K = 6, # K is the number of 'topics' (clusters)
verbose = FALSE)
p_beta <- tidy(topic_model, matrix = "frex") %>%
left_join(tidy(topic_model)) %>%
group_by(topic) %>%
slice_head(n = 20) %>%
mutate(topic = paste0("topic ", topic)) %>%
ggplot(aes(x = beta, y = reorder(term, beta), fill = topic)) +
geom_col() +
labs(y = "Word") +
facet_wrap(vars(topic), scales = "free", nrow = 1)
# Topic probabilities
group_gamma <- tidy(
topic_model,
matrix = "gamma",
document_names = rownames(sparse_mat)) %>%
mutate(chapter = factor(document)) %>%
dplyr::select(chapter, topic, gamma) %>%
mutate(topic = factor(topic)
)
p_gamma <- group_gamma %>%
filter(gamma > 0.01 ) %>%
ggplot(aes(x = topic, y = gamma, color = topic)) +
geom_point(aes(alpha = gamma)) +
geom_text_repel(aes(alpha = gamma, label = chapter), size = 5,
max.overlaps = 50) +
labs(y = expression(gamma), x = "") +
ggtitle("Corpus (character) strength of association with each topic") +
theme(legend.position = "none",
axis.text.x = element_blank())
(p_gamma / p_beta)
p_gamma <- group_gamma %>%
filter(gamma > 0.01 ) %>%
ggplot(aes(x = topic, y = gamma, color = topic)) +
geom_point(aes(alpha = gamma)) +
geom_text_repel(aes(alpha = gamma, label = chapter), size = 3,
max.overlaps = 50) +
labs(y = expression(gamma), x = "") +
ggtitle("Corpus (character) strength of association with each topic") +
theme(legend.position = "none",
axis.text.x = element_blank())
(p_gamma / p_beta)
